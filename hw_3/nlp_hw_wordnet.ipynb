{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e7715e-4cd6-4b6b-af22-e19a2ca8ab6b",
   "metadata": {},
   "source": [
    "# Ответы на вопросы:\n",
    "\n",
    "1. Сколько в списке пар слов синонимов: **8**\n",
    "\n",
    "2. Сколько в списке пар слов, связанных отношением гипоним-гипероним: **16**\n",
    "\n",
    "3. Сколько в списке пар слов связано другими типами отношений: **3**\n",
    "\n",
    "4. Средний вес близости у всех трех групп:\n",
    "\n",
    "    Синонимы: **8.772**\n",
    "\n",
    "    Гипонимы и гиперонимы: **8.156**\n",
    "\n",
    "    Другие типы отношений: **7.563**\n",
    "    \n",
    "Также посчитано среднее сходство слов, для которых не нашлось никакого отношения: **4.673**\n",
    "\n",
    "Среднее сходство пар внутри каждой из групп и полные списки пар, связанные заданным типом отношения -- в конце ноутбука"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e807dbe-6d24-4dca-8494-c18bd87f901e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c800d23d-ef80-4c51-9b3a-7d8973071705",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q http://alfonseca.org/pubs/ws353simrel.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "084f6db4-5fb7-4405-b9c3-9a47af3ff720",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar  xf ws353simrel.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba76e844-c76b-43d0-a909-157c5c6183f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/c204/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52211fb-5bbf-4170-8df8-f8f3c59d6c11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from typing import Dict, List, Tuple\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eafd2444-aa9e-4e35-b183-d6102f8db9fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_similarity_pairs(inp_path: str, sep='\\t'):\n",
    "    word_similarity_triples: List[Tuple[str, str, float]] = []\n",
    "    with open(inp_path, 'r', encoding=\"utf-8\") as inp_file:\n",
    "        for line in inp_file:\n",
    "            attrs = line.strip().split(sep)\n",
    "            word_1 = attrs[0] # .lower()\n",
    "            word_2 = attrs[1] # .lower()\n",
    "            similarity = float(attrs[2])\n",
    "            word_similarity_triples.append((word_1, word_2, similarity))\n",
    "    return word_similarity_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d2bb96-ac19-4887-8b14-7c1ebcf0c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synsets_list2lemma_list(synsets_list, ):\n",
    "    lemmas = set()\n",
    "    for synset in synsets_list:\n",
    "        # Получение списка лемм конкретного синсета\n",
    "        synset_lemmas = set((x.lower() for x in synset.lemma_names()))\n",
    "        # Обновление списка лемм леммами конкретного синсета\n",
    "        lemmas.update(synset_lemmas)\n",
    "    return lemmas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f4352b-4a39-445e-9677-eb0136820063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_synsets_by_name(wn, name: str):\n",
    "    synset_relation_lemmas = {}\n",
    "\n",
    "    # Получаем список возможных синонимов слова, используя функцию synonyms()\n",
    "    synset_relation_lemmas[\"synonym\"] = [synonym for synonym in itertools.chain(*wn.synonyms(name))]\n",
    "    # Получение списка синсентов, среди имён которых содержится данной слово\n",
    "    possible_synsets_of_name = wn.synsets(name)\n",
    "    \n",
    "    hypernym_lemmas = set()\n",
    "    hyponym_lemmas = set()\n",
    "    meronym_lemmas = set()\n",
    "    holonym_lemmas = set()\n",
    "    antonym_lemmas = set()\n",
    "    drf_lemmas = set()\n",
    "    pertainym_lemmas = set()\n",
    "    # Обход списка синсетов\n",
    "    for synset in possible_synsets_of_name:\n",
    "        if name not in synset.lemma_names():\n",
    "            continue\n",
    "        synset_name = synset.name()\n",
    "        # Обработка гипонимов\n",
    "        hypo_synsets = synset.hyponyms()\n",
    "        hypo_synset_lemmas = synsets_list2lemma_list(hypo_synsets, )\n",
    "        hyponym_lemmas.update(hypo_synset_lemmas)\n",
    "            \n",
    "        # Обработка гиперонимов\n",
    "        hyper_synsets = synset.hypernyms()\n",
    "        hyper_synset_lemmas = synsets_list2lemma_list(hyper_synsets, )\n",
    "        hypernym_lemmas.update(hyper_synset_lemmas)\n",
    "        \n",
    "        # Обработка part-меронимов \n",
    "        part_meronym_synsets =  synset.part_meronyms()\n",
    "        part_meronym_synset_lemmas = synsets_list2lemma_list(part_meronym_synsets, )\n",
    "        meronym_lemmas.update(part_meronym_synset_lemmas)\n",
    "        \n",
    "        # Обработка member-меронимов \n",
    "        member_meronym_synsets =  synset.member_meronyms()\n",
    "        member_meronym_synset_lemmas = synsets_list2lemma_list(member_meronym_synsets, )\n",
    "        meronym_lemmas.update(member_meronym_synset_lemmas)\n",
    "        \n",
    "        # Обработка substance-меронимов \n",
    "        substance_meronym_synsets =  synset.substance_meronyms()\n",
    "        substance_meronym_synset_lemmas = synsets_list2lemma_list(substance_meronym_synsets, )\n",
    "        meronym_lemmas.update(substance_meronym_synset_lemmas)\n",
    "        \n",
    "        # Обработка part-холонимов \n",
    "        part_holonym_synsets =  synset.part_holonyms()\n",
    "        part_holonym_synset_lemmas = synsets_list2lemma_list(part_holonym_synsets, )\n",
    "        holonym_lemmas.update(part_holonym_synset_lemmas)\n",
    "        \n",
    "        # Обработка member-холонимов \n",
    "        member_holonym_synsets =  synset.member_holonyms()\n",
    "        member_holonym_synset_lemmas = synsets_list2lemma_list(member_holonym_synsets, )\n",
    "        holonym_lemmas.update(member_holonym_synset_lemmas)\n",
    "        \n",
    "        # Обработка substance-холонимов \n",
    "        substance_holonym_synsets =  synset.substance_holonyms()\n",
    "        substance_holonym_synset_lemmas = synsets_list2lemma_list(substance_holonym_synsets, )\n",
    "        holonym_lemmas.update(substance_holonym_synset_lemmas)\n",
    "    \n",
    "\n",
    "        # Обработка отношений, заданных только для синонимов: antonyms, derivationally_related_forms and pertainyms\n",
    "        synset_lemma_id = f\"{synset_name}.{name}\"\n",
    "        synset_lemma = wn.lemma(synset_lemma_id)\n",
    "        # Обработка лемм-антонимов\n",
    "        lemma_level_antonym_lemma_ids = synset_lemma.antonyms()\n",
    "        lemma_level_antonym_lemma_names = [lemma_id.name().split('.')[-1].lower() for lemma_id in lemma_level_antonym_lemma_ids]\n",
    "        antonym_lemmas.update(lemma_level_antonym_lemma_names)\n",
    "\n",
    "        # Обработка лемм с отношением \"pertainym\"\n",
    "        lemma_level_pertainym_lemma_ids = synset_lemma.pertainyms()\n",
    "        lemma_level_pertainym_lemma_names = [lemma_id.name().split('.')[-1].lower() for lemma_id in lemma_level_pertainym_lemma_ids]\n",
    "        pertainym_lemmas.update(lemma_level_pertainym_lemma_names)\n",
    "\n",
    "        # Обработка лемм с отношением \"derivationally_related_forms\"\n",
    "        lemma_level_drf_lemma_ids = synset_lemma.derivationally_related_forms()\n",
    "        lemma_level_drf_lemma_names = [lemma_id.name().split('.')[-1].lower() for lemma_id in lemma_level_drf_lemma_ids]\n",
    "        drf_lemmas.update(lemma_level_drf_lemma_names)\n",
    "    \n",
    "    other_lemmas = set()\n",
    "    other_lemmas.update(meronym_lemmas)\n",
    "    other_lemmas.update(holonym_lemmas)\n",
    "    other_lemmas.update(antonym_lemmas)\n",
    "    other_lemmas.update(drf_lemmas)\n",
    "    other_lemmas.update(pertainym_lemmas)\n",
    "    synset_relation_lemmas[\"hyponym-hypernym\"] = hypernym_lemmas.union(hyponym_lemmas)\n",
    "    # synset_relation_lemmas[\"hyponym\"] = hyponym_lemmas\n",
    "    # synset_relation_lemmas[\"meronym-holonym\"] = meronym_lemmas.union(holonym_lemmas)\n",
    "    # synset_relation_lemmas[\"holonym\"] = holonym_lemmas\n",
    "    synset_relation_lemmas[\"other\"] = antonym_lemmas.union(drf_lemmas).union(pertainym_lemmas)\n",
    "    # synset_relation_lemmas[\"antonym\"] = antonym_lemmas\n",
    "    # synset_relation_lemmas[\"derivationally_related_forms\"] = drf_lemmas\n",
    "    # synset_relation_lemmas[\"pertainym\"] = pertainym_lemmas\n",
    "    \n",
    "    return synset_relation_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9211ea6f-1b06-4c81-99f0-c47bc55c5ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relation_synsets_for_words(wn, words_list):\n",
    "    # Для каждого слова из заданного списка функция находит слова,\n",
    "    # связанные с заданным некоторым отношением\n",
    "    word_relation_info = {}\n",
    "    for word in words_list:\n",
    "        synset_relation_lemmas_dict = process_synsets_by_name(wn, word)\n",
    "        word_relation_info[word] = synset_relation_lemmas_dict\n",
    "    return word_relation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e75d690-ca61-4eae-bfbf-98e26be10083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_vocab_from_similarity_triples(triples):\n",
    "    # Получение списка уникальных слов для слов из списка wordsim353\n",
    "    vocab = set()\n",
    "    for (word_1, word_2, sim) in triples:\n",
    "        vocab.add(word_1)\n",
    "        vocab.add(word_2)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d64455-a2d7-4cf3-995d-680641235c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_sim_pairs_by_rel_type(sim_triples, word_relation_info):\n",
    "    # Для каждой пары слов из wordsim353 функция находит тип отношения между ними.\n",
    "    # Пары слов группируются по типу отношения. Отсутствие отношения также запоминается\n",
    "    rel_types = [\"synonym\", \"hyponym-hypernym\", \"other\"]\n",
    "    word_pairs_grouped_by_rel_type = {}\n",
    "    word_pairs_grouped_by_rel_type = {r_t: set() for r_t in rel_types}\n",
    "    rel_types = tuple(word_pairs_grouped_by_rel_type.keys())\n",
    "    for t in sim_triples:\n",
    "        (word_1, word_2, similarity) = t\n",
    "        (word_1, word_2) = (word_1, word_2) if word_1 < word_2 else (word_2, word_1)\n",
    "        assert '||' not in  word_1 and '||' not in  word_2\n",
    "        found_rel = False\n",
    "        for rel_type in rel_types:\n",
    "            if word_2.lower() in word_relation_info[word_1][rel_type] or \\\n",
    "                    word_1.lower() in word_relation_info[word_2][rel_type]:\n",
    "                \n",
    "                word_pairs_grouped_by_rel_type[rel_type].add(f\"{word_1}||{word_2}||{similarity}\")\n",
    "                found_rel = True\n",
    "        # Если для пары слов не нашлось отношения, запоминаем,\n",
    "        # что отношение между ними не найдено\n",
    "        if not found_rel:\n",
    "            if word_pairs_grouped_by_rel_type.get(\"no_relation\") is None:\n",
    "                word_pairs_grouped_by_rel_type[\"no_relation\"] = set()\n",
    "            word_pairs_grouped_by_rel_type[\"no_relation\"].add(f\"{word_1}||{word_2}||{similarity}\")\n",
    "    for rel_type in word_pairs_grouped_by_rel_type.keys():\n",
    "        w_pairs_set = word_pairs_grouped_by_rel_type[rel_type]\n",
    "        w_pairs_split = []\n",
    "        for pair in w_pairs_set:\n",
    "            attrs = pair.split('||')\n",
    "            w_1 = attrs[0]\n",
    "            w_2 = attrs[1]\n",
    "            sim = float(attrs[2])\n",
    "            t = (w_1, w_2, sim)\n",
    "            w_pairs_split.append(t)\n",
    "        word_pairs_grouped_by_rel_type[rel_type] = w_pairs_split\n",
    "            \n",
    "    return word_pairs_grouped_by_rel_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d385805b-50bd-4f83-93d7-498bb3736337",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_path = \"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n",
    "word_similarity_triples = load_similarity_pairs(inp_path=similarities_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b384af6a-cf9b-47cf-8eb4-345b386422cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_vocab_from_similarity_triples(word_similarity_triples)\n",
    "word_relation_info = find_relation_synsets_for_words(wn, words_list=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fedb146a-4b4e-4e16-a493-1d81ff0b8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs_grouped_by_rel_type = group_sim_pairs_by_rel_type(word_similarity_triples,\n",
    "                                                             word_relation_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe01f599-b4cd-47c3-b7d0-c2f80302d781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_pairs_info_by_rel_type(word_pairs_grouped_by_rel_type):\n",
    "    pairs_by_rel_type = {}\n",
    "    scores_sum_by_rel_type = {}\n",
    "    pair_count_by_rel_type = {}\n",
    "    for rel_type, triplets in word_pairs_grouped_by_rel_type.items():\n",
    "        if len(triplets) == 0:\n",
    "            continue\n",
    "        # scores_sum_by_rel_type.get(rel_type) is None:\n",
    "        #     scores_sum_by_rel_type[rel_type] = []\n",
    "        #     pair_count_by_rel_type[rel_type] = []\n",
    "        scores_sum = sum(t[2] for t in triplets)\n",
    "        pair_count = len(triplets)\n",
    "        pairs_by_rel_type[rel_type] = [(t[0], t[1]) for t in triplets]\n",
    "        scores_sum_by_rel_type[rel_type] = scores_sum\n",
    "        pair_count_by_rel_type[rel_type] = pair_count\n",
    "\n",
    "    return pairs_by_rel_type, scores_sum_by_rel_type, pair_count_by_rel_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e09ded80-7de2-43d4-9b14-943731eeb32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs_by_rel_type, scores_sum_by_rel_type, pair_count_by_rel_type \\\n",
    "        = group_pairs_info_by_rel_type(word_pairs_grouped_by_rel_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565ca81-0965-47a9-88b8-c4c3ce4c6fcc",
   "metadata": {},
   "source": [
    "## Число пар и среднее сходство пар разных типов отношений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad026123-8341-4d3b-96eb-244fd9fe0491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип отношения: synonym, число пар: 8, средняя близость: 8.772\n",
      "Тип отношения: hyponym-hypernym, число пар: 16, средняя близость: 8.156\n",
      "Тип отношения: other, число пар: 3, средняя близость: 7.563\n",
      "Тип отношения: no_relation, число пар: 177, средняя близость: 4.673\n"
     ]
    }
   ],
   "source": [
    "for key in scores_sum_by_rel_type.keys():\n",
    "    scores_sum = scores_sum_by_rel_type[key]\n",
    "    pair_count = pair_count_by_rel_type[key]\n",
    "    \n",
    "    mean_sim = scores_sum / pair_count\n",
    "    print(f\"Тип отношения: {key}, число пар: {pair_count}, средняя близость: {mean_sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716da316-6801-4838-bef3-74cff4d0adf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Списки пар слов, сгруппированные по типу отношения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a070c5bf-a01e-4bcd-87e6-d4bda6923b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип отношения: synonym\n",
      "\tbuck - dollar\n",
      "\tgem - jewel\n",
      "\tking - queen\n",
      "\tcalculation - computation\n",
      "\tmagician - wizard\n",
      "\tautomobile - car\n",
      "\tmidday - noon\n",
      "\tforest - wood\n",
      "Тип отношения: hyponym-hypernym\n",
      "\tliquid - water\n",
      "\tjourney - voyage\n",
      "\tboy - lad\n",
      "\tcat - tiger\n",
      "\taluminum - metal\n",
      "\tcurrency - money\n",
      "\tcat - jaguar\n",
      "\tkind - type\n",
      "\tfootball - soccer\n",
      "\texample - precedent\n",
      "\tavenue - street\n",
      "\tcoast - shore\n",
      "\tpsychology - science\n",
      "\tfood - seafood\n",
      "\tbird - cock\n",
      "\tasylum - madhouse\n",
      "Тип отношения: other\n",
      "\tman - woman\n",
      "\tsmart - stupid\n",
      "\tking - queen\n"
     ]
    }
   ],
   "source": [
    "for rel_type, pairs in pairs_by_rel_type.items():\n",
    "    if rel_type != \"no_relation\":\n",
    "        print(f\"Тип отношения: {rel_type}\")\n",
    "        for (w1, w2) in pairs:\n",
    "            print(f\"\\t{w1} - {w2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af53bf-9e2c-42a0-a448-27a60e7e2fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
